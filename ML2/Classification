# Classification

지도학습의 대표적인 유형인 분류는 기존데이터가 어떤 레이블에 속하는지 패턴을 알고리즘으로 인지한 뒤에 새롭게 관측된 데이터에 대한 레이블을 판별하는 것이다

다양한 머신러닝 알고리즘

- 나이브 베이즈 : 베이즈 통계와 생성 모델에 기반
- 로지스틱 회귀 : 독립변수와 종속변수의 선형 관계성에 기반
- 결정트리 : 데이터 균일도에 따른 규칙 기반의 결정 트리
- 서포트 벡터 머신 : 개별 클래스 간의 최대 분류 마진을 효과적으로 찾아준다
- 신경망 : 심층 연결 기반
- 앙상블 : 서로 다른 or 같은 머신러닝 알고리즘을 결합

## 결정 트리

ML알고리즘 중 직관적으로 이해하기 쉬운 알고리즘이다.

많은 노드(깊음)를 생성한다면 그만큼 복잡해 진다는 얘기고, 그 결과로 과적합이 발생한다.

- 규칙 노드 : 규칙 조건
- 리프 노드 : 결정된 클래스
- 서브 노드 : 균일한 데이터 세트로 분할

균일도가 높은 세트(같은 모집단)를 순서대로 나열하면 된다.

---

### 균일도 측정 by 엔트로피

- 정보 이득 : 엔트로피라는 개념을 기반으로 한다.
    - 엔트로피는 주어진 데이터 집합의 혼잡도를 의미
    - 서로 다른 값이 섞여 있으면 엔트로피가 높고, 같은 값이 섞여 있으면 엔트로피가 낮다
    - 정보 이득 지수 = (1 - 엔트로피 지수)
    - 결정 트리는 이 정보 이득 지수로 분할 기준을 정한다.
    - 정보 이득이 높은 속성을 기준으로 분할
- 지니 계수 : 0이 가장 평등, 1이 가장 불평등
    - 지니 계수가 낮을수록 데이터 균일도가 높은 것으로 해석해 지니 계수가 낮은 속성을 기준으로 분할

### 결정 트리 모델의 특징

- 균일도를 기반
- 전처리 필요 x
- 과적합으로 정확도가 떨어진다.

### 결정 트리 파라미터

- min_samples_split :
    - 노드를 분할하기 위한 최소한의 샘플 데이터 수로 과적합을 제어하는 데 사용
    - 디폴트 = 2, 작게 설정할수록 분할되는 노드가 많아져서 과적합 가능성 증가
- min_samples_leaf
    - 분할이 될 경우 왼쪽과 오른쪽의 브랜치 노드에서 가져야 할 최소한의 샘플 데이터 수
    - 큰 값으로 설정될수록, 분할된 경우 왼쪽과 오른쪽의 브랜치 노드에서 가져야 할 최소한의 샘플 데이터 수 조건을 만족시키기 어려움
    - 과적합 제어 용도
- max_features
    - 최적의 분할을 위해 고려할 최대 피처 개수, 디폴트는 None로 데이터 세트의 모든 피처를 사용해 분할 수행
    - int형으로 지정하면 대상 피처의 개수, float형으로 지정하면 전체 피처 중 대상 피처의 퍼센트
- max_depth
    - 트리의 최대 깊이를 규정
- max_leaf_nodes
    - 말단 노드의 최대 개수
