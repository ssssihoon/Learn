[https://www.youtube.com/watch?v=BKhbF_KonH0&list=PL13IrJom4GzssqejzOqR2S0OukBIyufjy&index=4](https://www.youtube.com/watch?v=BKhbF_KonH0&list=PL13IrJom4GzssqejzOqR2S0OukBIyufjy&index=4)


- [축구선수 시장가치 분석](#축구선수-시장가치-분석)
- [Requests](#requests)
- [BeautifulSoup](#beautifulsoup)
  - [첫 번째 tag의 정보를 가져오기](#첫-번째-tag의-정보를-가져오기)
  - [첫 번째 tag의 속성 정보 가져오기](#첫-번째-tag의-속성-정보-가져오기)
    - [전체 a를 가져오기](#전체-a를-가져오기)
  - [텍스트만 가져오기](#텍스트만-가져오기)
- [크롤링 예제](#크롤링-예제)
    - [p 태그 정보 가져오기 (처음 나오는 것 한 개)](#p-태그-정보-가져오기-처음-나오는-것-한-개)
    - [a 태그에 있는 ‘href’ 속성값 가져오기 (처음 나오는 것 한 개)](#a-태그에-있는-href-속성값-가져오기-처음-나오는-것-한-개)
    - [a 태그에 있는 텍스트 가져오기 (처음 나오는 것 한 개)](#a-태그에-있는-텍스트-가져오기-처음-나오는-것-한-개)
    - [a 태그에 있는 요소들 모두 가져오기](#a-태그에-있는-요소들-모두-가져오기)
    - [두 번째 a 태그에 있는 정보 가져오기](#두-번째-a-태그에-있는-정보-가져오기)
    - [a 태그에 있는 ‘href’속성값 모두 가져오기](#a-태그에-있는-href속성값-모두-가져오기)
    - [a 태그에 있는 텍스트 모두 가져오기](#a-태그에-있는-텍스트-모두-가져오기)
    - [a 태그이면서 class가 sister인 값 모두 찾아오기](#a-태그이면서-class가-sister인-값-모두-찾아오기)
    - [a 태그이면서 id가 link3인 요소들 모두 찾기](#a-태그이면서-id가-link3인-요소들-모두-찾기)
- [축구선수 시장가치 분석](#축구선수-시장가치-분석-1)
  - [선수들의 정보가 담긴 태그와 클래스 찾기](#선수들의-정보가-담긴-태그와-클래스-찾기)
    - [첫 번째 요소 확인하기](#첫-번째-요소-확인하기)
    - [전체 개수 확인하기](#전체-개수-확인하기)
    - [7개 정보를 담을 빈 리스트 만들기](#7개-정보를-담을-빈-리스트-만들기)
    - [player\_info에서 ‘td’태그만 모두 찾기, 해당 정보를 찾아서 각 리스트에 .append로 추가하기](#player_info에서-td태그만-모두-찾기-해당-정보를-찾아서-각-리스트에-append로-추가하기)
  - [데이터프레임으로 저장하기](#데이터프레임으로-저장하기)
  - [df를 csv파일로 저장하기](#df를-csv파일로-저장하기)
  - [여러 페이지 크롤링하기](#여러-페이지-크롤링하기)
- [데이터 전처리](#데이터-전처리)
  - [iloc와 loc](#iloc와-loc)
    - [loc](#loc)
    - [예제)](#예제)
- [DataFrame 정렬하기와 컬럼 바꾸기](#dataframe-정렬하기와-컬럼-바꾸기)
  - [정렬하기](#정렬하기)
    - [인덱스 순으로 정렬하기](#인덱스-순으로-정렬하기)
    - [내림차순으로 정렬하기](#내림차순으로-정렬하기)
    - [sort\_values로 정렬하기](#sort_values로-정렬하기)
    - [인덱스를 컬럼이름으로 바꾸기](#인덱스를-컬럼이름으로-바꾸기)
  - [컬럼이름 바꾸기](#컬럼이름-바꾸기)
    - [컬럼이름 바꾸고 저장하기](#컬럼이름-바꾸고-저장하기)
  - [데이터 전처리](#데이터-전처리-1)
  - [컬럼 생성과 삭제](#컬럼-생성과-삭제)
    - [컬럼 생성](#컬럼-생성)
    - [컬럼 삭제](#컬럼-삭제)
- [DataFrame 통계분석과 groupby](#dataframe-통계분석과-groupby)
    - [숫자형 데이터에 대한 통계](#숫자형-데이터에-대한-통계)
    - [평균구하기](#평균구하기)
    - [최빈값 구하기](#최빈값-구하기)
  - [Groupby](#groupby)
    - [그룹화된 합계](#그룹화된-합계)
# 축구선수 시장가치 분석



유튜브 자료를 참고했습니다.

# Requests

- 웹페이지 읽어오기

[https://requests.readthedocs.io/en/master/](https://requests.readthedocs.io/en/master/)

```python
r = requests.get('https://api.github.com/user', auth=('user', 'pass'))
r.status_code

'''
200
''' 
Ok라는 뜻
```

200이라는 것이 안나오면

구글에 “my user agent” 검색

‘’’

Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36

‘’’

복사해서 headers에 넣어준다.

```python
headers = {'User-Agent' : 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36'}
url = "접속할 사이트"
requests.get(url, headers = headers)
```

```python
import requests

headers = {'User-Agent' : 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36'}
url = 'https://www.transfermarkt.com/spieler-statistik/wertvollstespieler/marktwertetop'

r = requests.get(url, headers=headers)
print(r.status_code)

'''
200
'''
```

# BeautifulSoup

- 원하는 데이터 가져오기(스크래핑)
- HTML, XML 파일 데이터를 끄집어내는 라이브러리
- html_doc 는 문서

```python
from bs4 import BeautifulSoup

html_doc = """<html><head><title>The Dormouse's story</title></head>
<body>
<p class="title"><b>The Dormouse's story</b></p>

<p class="story">Once upon a time there were three little sisters; and their names were
<a href="http://example.com/elsie" class="sister" id="link1">Elsie</a>,
<a href="http://example.com/lacie" class="sister" id="link2">Lacie</a> and
<a href="http://example.com/tillie" class="sister" id="link3">Tillie</a>;
and they lived at the bottom of a well.</p>

<p class="story">...</p>
"""

soup = BeautifulSoup(html_doc, 'html.parser')
print(soup.prettify())
```

## 첫 번째 tag의 정보를 가져오기

soup.tag명

soup.find(’tag명’)

```python
<p
''''

''''
</p>

p내에 정보를 쓴다 하면

soup.p를 이용해 쓰면 된다.

```

## 첫 번째 tag의 속성 정보 가져오기

soup.tag명[’속성명’]

soup.find(’tag명’)[’속성명’]

ex:) href

### 전체 a를 가져오기

soup.find_all(’a’)

→결과는 리스트타입이다.

## 텍스트만 가져오기

- .text

```python
soup.find('a').text

'''
'Elsie'
'''
```

# 크롤링 예제

기본 정보

```python
import requests
from bs4 import BeautifulSoup

headers = {'User-Agent' : 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36'}
url = 'https://www.transfermarkt.com/'
r = requests.get(url, headers=headers)

html_doc = """<html><head><title>The Dormouse's story</title></head>
<body>
<p class="title"><b>The Dormouse's story</b></p>

<p class="story">Once upon a time there were three little sisters; and their names were
<a href="http://example.com/elsie" class="sister" id="link1">Elsie</a>,
<a href="http://example.com/lacie" class="sister" id="link2">Lacie</a> and
<a href="http://example.com/tillie" class="sister" id="link3">Tillie</a>;
and they lived at the bottom of a well.</p>

<p class="story">...</p>
"""

soup = BeautifulSoup(html_doc, 'html.parser')
```

### p 태그 정보 가져오기 (처음 나오는 것 한 개)

```python
print(soup.p)

'''
<p class="title"><b>The Dormouse's story</b></p>
'''
```

### a 태그에 있는 ‘href’ 속성값 가져오기 (처음 나오는 것 한 개)

```python
print(soup.a['href'])

'''
http://example.com/elsie
'''
```

### a 태그에 있는 텍스트 가져오기 (처음 나오는 것 한 개)

```python
print(soup.find('a').text)

'''
Elsie
'''
```

### a 태그에 있는 요소들 모두 가져오기

```python
print(soup.find_all('a'))

'''
[<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>, <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>, <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]
'''
리스트 형식이다.
```

### 두 번째 a 태그에 있는 정보 가져오기

```python
print(soup.find_all('a')[1])

'''
<a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>
'''
```

### a 태그에 있는 ‘href’속성값 모두 가져오기

```python
a_list = soup.find_all('a')
for i in a_list:
    print(i['href'])

'''
http://example.com/elsie
http://example.com/lacie
http://example.com/tillie
'''
```

### a 태그에 있는 텍스트 모두 가져오기

```python
a_list = soup.find_all('a')
for i in a_list:
    print(i.text)

'''
Elsie
Lacie
Tillie
'''
```

### a 태그이면서 class가 sister인 값 모두 찾아오기

```python
print(soup.find_all('a', class_ = 'sister'))

'''
[<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>, <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>, <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]
'''
class가 키워드로 인식되므로 class_사용
```

### a 태그이면서 id가 link3인 요소들 모두 찾기

```python
print(soup.find_all('a', id='link3'))

'''
[<a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]
'''
```

# 축구선수 시장가치 분석

<축구 선수 시장>

[https://www.transfermarkt.com/spieler-statistik/wertvollstespieler/marktwertetop](https://www.transfermarkt.com/spieler-statistik/wertvollstespieler/marktwertetop)

data set

```python
import requests
from bs4 import BeautifulSoup
import pandas as pd
import time

headers = {'User-Agent' : 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36'}
url = 'https://www.transfermarkt.com/spieler-statistik/wertvollstespieler/marktwertetop'
r = requests.get(url, headers=headers)

soup = BeautifulSoup(r.content, 'html.parser')
print(soup)
```

## 선수들의 정보가 담긴 태그와 클래스 찾기

현재 선수들의 정보가

태그는 tr , class = odd 또는 class = even에 담겨져있다.

### 첫 번째 요소 확인하기

```python
player_info = soup.find_all('tr', class_ = ['odd', 'even'])
print(player_info[0])

'''
<tr class="odd">
<td class="zentriert">1</td><td class=""><table class="inline-table"><tr><td rowspan="2"><a href="#"><img alt="Erling Haaland" class="bilderrahmen-fixed" src="https://img.a.transfermarkt.technology/portrait/small/418560-1656179352.jpg?lm=1" title="Erling Haaland"/></a></td><td class="hauptlink"><a href="/erling-haaland/profil/spieler/418560" title="Erling Haaland">Erling Haaland</a></td></tr><tr><td>Centre-Forward</td></tr></table></td><td class="zentriert">23</td><td class="zentriert"><img alt="Norway" class="flaggenrahmen" src="https://tmssl.akamaized.net/images/flagge/verysmall/125.png?lm=1520611569" title="Norway"/></td><td class="zentriert"><a href="/manchester-city/startseite/verein/281" title="Manchester City"><img alt="Manchester City" class="" src="https://tmssl.akamaized.net/images/wappen/verysmall/281.png?lm=1467356331" title="Manchester City"/></a></td><td class="rechts hauptlink"><a href="/erling-haaland/marktwertverlauf/spieler/418560">€180.00m</a> </td></tr>
'''
```

### 전체 개수 확인하기

```python
print(len(player_info))

'''
25
'''
```

### 7개 정보를 담을 빈 리스트 만들기

- number, name, position, age, nation, team, value

```python
number = []
name = []
position = []
age = []
nation = []
team = []
value = []
```

td태그에서 정보들이 다 담겨져 있었다.

### player_info에서 ‘td’태그만 모두 찾기, 해당 정보를 찾아서 각 리스트에 .append로 추가하기

```python
for info in player_info:
    player = info.find_all('td')
    print(player[0])

'''
<td class="zentriert">1</td>
<td class="zentriert">2</td>
<td class="zentriert">3</td>
<td class="zentriert">4</td>
<td class="zentriert">5</td>
<td class="zentriert">6</td>
<td class="zentriert">7</td>
<td class="zentriert">8</td>
<td class="zentriert">9</td>
<td class="zentriert">10</td>
<td class="zentriert">11</td>
<td class="zentriert">12</td>
<td class="zentriert">13</td>
<td class="zentriert">14</td>
<td class="zentriert">15</td>
<td class="zentriert">16</td>
<td class="zentriert">17</td>
<td class="zentriert">18</td>
<td class="zentriert">19</td>
<td class="zentriert">20</td>
<td class="zentriert">21</td>
<td class="zentriert">22</td>
<td class="zentriert">23</td>
<td class="zentriert">24</td>
<td class="zentriert">25</td>
'''
순위들이 담겨져있다. ->number
```

각 인덱스별로 append로 빈 리스트에 넣기만 하면 됨.

```python
for info in player_info:
    player = info.find_all('td')
    number.append(player[0].text)
print(number)

'''
['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25']
'''

```

```python
for info in player_info:
    player = info.find_all('td')
    number.append(player[0].text)
    name.append(player[3].text)
    position.append(player[4].text)
    age.append(player[5].text)
    nation.append(player[6].img['alt'])
    team.append(player[7].img['alt'])
    value.append(player[8].text.strip())
```

## 데이터프레임으로 저장하기

```python
df = pd.DataFrame(
    {'number' : number,
     'name' : name,
     'position' : position,
     'age' : age,
     'nation' : nation,
     'team' : team,
     'value' : value}
)
print(df.head())

'''
  number             name  ...                 team     value
0      1   Erling Haaland  ...      Manchester City  €180.00m
1      2    Kylian Mbappé  ...  Paris Saint-Germain  €180.00m
2      3  Vinicius Junior  ...          Real Madrid  €150.00m
3      4  Jude Bellingham  ...          Real Madrid  €120.00m
4      5      Bukayo Saka  ...           Arsenal FC  €120.00m

[5 rows x 7 columns]
'''
```

## df를 csv파일로 저장하기

- df.to_csv()

```python
df.to_csv('transfermakt25.csv', index = False)
```

transfermakt25명으로 저장된다.

## 여러 페이지 크롤링하기

- 두 번째 페이지 까지 총 50명 정보 크롤링

구조가 똑같기 때문에 url주소만 변경하면 된다.

for 문을 통해 여러개의 페이지를 크롤링할 수 있다.

- url 적을 때 조심 f””

```python
import requests
from bs4 import BeautifulSoup
import pandas as pd
import time

number = []
name = []
position = []
age = []
nation = []
team = []
value = []

for i in range(1, n + 1):  # n 은 페이지 수
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36'}
    url = **f**'https://www.transfermarkt.com/spieler-statistik/wertvollstespieler/marktwertetop/page={**i**}'
    r = requests.get(url, headers=headers)

    soup = BeautifulSoup(r.content, 'html.parser')
    player_info = soup.find_all('tr', class_=['odd', 'even'])
    for info in player_info:
        player = info.find_all('td')
        number.append(player[0].text)
        name.append(player[3].text)
        position.append(player[4].text)
        age.append(player[5].text)
        nation.append(player[6].img['alt'])
        team.append(player[7].img['alt'])
        value.append(player[8].text.strip())

        time.sleep(1)  # 1초만 휴식

df = pd.DataFrame(
    {'number': number,
     'name': name,
     'position': position,
     'age': age,
     'nation': nation,
     'team': team,
     'value': value}
)

df.to_csv('transfermakt25.csv', index=False)
```

csv파일을 열었을 때 문자 깨짐 현상이 일어나면 

excel에서 데이터 → 데이터 가져오기 → csv파일 선택 → 다른이름으로 저장 →xlsx파일로 저장

# 데이터 전처리

df

```python
import pandas as pd

df = pd.read_csv("transfermakt.csv")
print(df.head())

'''
   number             name  ...                 team     value
0       1   Erling Haaland  ...      Manchester City  €180.00m
1       2    Kylian Mbappé  ...  Paris Saint-Germain  €180.00m
2       3  Vinicius Junior  ...          Real Madrid  €150.00m
3       4  Jude Bellingham  ...          Real Madrid  €120.00m
4       5      Bukayo Saka  ...           Arsenal FC  €120.00m

[5 rows x 7 columns]
'''
```

## iloc와 loc

```python
df.iloc[0:2]
==
df[0:2]
==
df.head(2)
```

### loc

loc는 인덱스 숫자(문자)를 기준으로 한다.

loc[0:2]면 0, 1, 2까지

iloc[0:2]면 0, 1까지

- 쉼표를 기준으로 행과 열 표시
    
    df.loc[행이름, 열이름]
    

### 예제)

- loc조건으로 나이가 30이상인 선수의 name과 value를 가져오세요

```python
print(df.loc[df['age']>=30][['name', 'value']])

'''
               name    value
16       Harry Kane  €90.00m
45  Kevin De Bruyne  €70.00m

'''
```

# DataFrame 정렬하기와 컬럼 바꾸기

## 정렬하기

### 인덱스 순으로 정렬하기

```python
df.sort_index()
```

### 내림차순으로 정렬하기

```python
df.sort_index(ascending = False)
```

### sort_values로 정렬하기

- sort_values(컬럼이름)

```python
# 나이 많은 선수 10명 보여주기

print(df.sort_values("age", ascending = False).head())
```

### 인덱스를 컬럼이름으로 바꾸기

```python
# number로 인덱스 바꾸기

df.set_index('number').head()
```

## 컬럼이름 바꾸기

### 컬럼이름 바꾸고 저장하기

- df.rename(columns = {’바꿀 컬럼명’ : ‘원하는 컬럼명’}
- df = df~ 로 재할당 해서 사용한다.
- 또는 inplace = True

```python
#team을 club으로 바꾸기

df.rename(columns = {'team' : 'club'}, inplace = True)
```

## 데이터 전처리

- replace(’바꿀 문자’, ‘원하는 문자’)
- astype(원하는 문자형)

```python
'''
value 값에서 불필요한 문자는 없애고 데이터타입을 숫자형으로 바꾸기
ex:) E90.00m -> 90.00
'''
df['value'].str.replace('E', '').astype(float)
df['value'].str.replace('m', '').astype(float)
```

## 컬럼 생성과 삭제

### 컬럼 생성

```python
# 시장가치가 유로로 돼있어서 이것을 한화로 새 컬럼을 만들고 싶다.
# (백만)유로 *13 -> 억원
df['시장가치(억)'] = df['value']*13
```

### 컬럼 삭제

- df.drop(columns = [’컬럼이름’])

```python
df.drop(columns=['value'], inplace=True)
```

# DataFrame 통계분석과 groupby

### 숫자형 데이터에 대한 통계

- df.describe()

```python
print(df.describe())

'''
         number        age
count  50.00000  50.000000
mean   25.50000  23.900000
std    14.57738   2.764572
min     1.00000  19.000000
25%    13.25000  22.000000
50%    25.50000  24.000000
75%    37.75000  25.750000
max    50.00000  32.000000
'''
```

### 평균구하기

- df[’컬럼명’].mean()

```python
#나이평균 구하기
df['age'].mean()
```

- 국적이 브라질인 선수들은?

```python
df[df['nation']=='Brazil']
```

### 최빈값 구하기

- 최빈값 : 빈도수
- df[’컬럼명’].mode()

## Groupby

데이터를 그룹으로 묶어분석

```python
# 국적에 따라
g = df.groupby('nation')
print(g.size())

'''
nation
Argentina      3
Belgium        1
Brazil         6
Canada         1
Colombia       1
Croatia        1
Ecuador        1
England        7
France         6
Georgia        1
Germany        3
Italy          1
Netherlands    2
Nigeria        1
Norway         2
Portugal       5
Serbia         1
Spain          3
Sweden         1
Uruguay        3
dtype: int64
'''
```

### 그룹화된 합계

```python
g.sum() #전체를 보여준다
g['value'].sum()
```