{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Loading the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OpenCV 라이브러리 import\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(1280, 1920, 3)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread('/Users/sihoon/Desktop/ComputerVision/Computer Vision Masterclass/Images/people1.jpg')\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-15 15:51:08.602 Python[62854:3446920] WARNING: Secure coding is not enabled for restorable state! Enable secure coding by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState: and returning YES.\n"
     ]
    }
   ],
   "source": [
    "cv2.imshow('Image', image)\n",
    "cv2.waitKey(0)  # 아무 키 입력 대기\n",
    "cv2.destroyAllWindows()  # 모든 윈도우 닫기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(600, 800, 3)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 보다 빠르게 이미지를 감지하려면 이미지의 크기를 줄이면 된다.\n",
    "image = cv2.resize(image, (800, 600)) # 800x600\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv2.imshow('Image', image)\n",
    "cv2.waitKey(0)  # 아무 키 입력 대기\n",
    "cv2.destroyAllWindows()  # 모든 윈도우 닫기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 컬러 -> 흑백\n",
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('Image', image_gray)\n",
    "cv2.waitKey(0)  # 아무 키 입력 대기\n",
    "cv2.destroyAllWindows()  # 모든 윈도우 닫기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 800)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_gray.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Use Haarcascade and OpenCV to Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 얼굴 탐지기(분류기) 설정\n",
    "face_detector = cv2.CascadeClassifier('/Users/sihoon/Desktop/ComputerVision/Computer Vision Masterclass/Cascades/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 모든 감지값을 저장하는 변수 설정\n",
    "detections = face_detector.detectMultiScale(image_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[387, 233,  73,  73],\n",
       "       [ 92, 239,  66,  66],\n",
       "       [115, 124,  53,  53],\n",
       "       [475, 123,  59,  59],\n",
       "       [677,  72,  68,  68],\n",
       "       [390, 323,  56,  56]], dtype=int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections\n",
    "\n",
    "# 열 row 의 개수 : 감지된 얼굴의 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(detections))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "여기서의 문제는 사진에 사람은 6명이지만 5명은 정면을 보고있고, 1명은 옆뒷면을 보이고 있다.\n",
    "근데 분류기의 이름을 보면 haarcascade_frontalface_default로 정면만을 인식해야한다. 즉 5이 되게끔 만들어야함. -> 목표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[387, 233,  73,  73],\n",
       "       [ 92, 239,  66,  66],\n",
       "       [115, 124,  53,  53],\n",
       "       [475, 123,  59,  59],\n",
       "       [677,  72,  68,  68],\n",
       "       [390, 323,  56,  56]], dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections\n",
    "\n",
    "# 컬럼 idx 첫 번째와 두 번째는 각각 x축, y축을 뜻함\n",
    "# 마지막 두 개는 얼굴의 크기(너비 width, 높이 height)를 나타 낸다. 73x73\n",
    "# 즉 얼굴의 위치를 나타냄."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387 233 73 73\n",
      "92 239 66 66\n",
      "115 124 53 53\n",
      "475 123 59 59\n",
      "677 72 68 68\n",
      "390 323 56 56\n"
     ]
    }
   ],
   "source": [
    "for (x, y, w, h) in detections:\n",
    "    print(x, y, w, h)\n",
    "    # 1 : 이미지, 2 : 직사각형이 시작되는 지점 3 : 선의 색깔, 4 : 선의 굵기\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "cv2.imshow('Image', image)\n",
    "cv2.waitKey(0)  # 아무 키 입력 대기\n",
    "cv2.destroyAllWindows()  # 모든 윈도우 닫기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Haarcascade Parameter1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('/Users/sihoon/Desktop/ComputerVision/Computer Vision Masterclass/Images/people1.jpg')\n",
    "image = cv2.resize(image, (800, 600))\n",
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "detections = face_detector.detectMultiScale(image_gray, scaleFactor=1.09)\n",
    "for (x, y, w, h) in detections:\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 5)\n",
    "cv2.imshow('Image', image)\n",
    "cv2.waitKey(0)  # 아무 키 입력 대기\n",
    "cv2.destroyAllWindows()  # 모든 윈도우 닫기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "OpenCV의 얼굴 감지 함수(face_detector.detectMultiScale())는 일반적으로 흑백 이미지를 입력으로 사용합니다. 흑백 이미지를 사용하면 컴퓨터 비전 작업의 성능이 향상되는 경우가 많습니다. 이유는 흑백 이미지는 컬러 이미지보다 채널 수가 적고, 처리량이 적기 때문입니다. 또한 얼굴 감지 알고리즘은 주로 명암 대비를 기반으로 동작하기 때문에 흑백 이미지를 더 선호합니다.\n",
    "\n",
    "따라서 얼굴 감지를 위해서는 일반적으로 컬러 이미지를 흑백 이미지로 변환하여 사용합니다. 이렇게 하면 처리 속도가 향상되며, 결과가 훨씬 더 정확해질 수 있습니다.\n",
    "\n",
    "따라서 주어진 코드에서 image_gray가 필요한 것입니다. 이 흑백 이미지를 사용하여 얼굴 감지를 수행하고, 그 결과를 원본 컬러 이미지에 사각형으로 표시합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Haarcascade Parameter2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('/Users/sihoon/Desktop/ComputerVision/Computer Vision Masterclass/Images/people2.jpg')\n",
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "detections = face_detector.detectMultiScale(image_gray, scaleFactor=1.2, minNeighbors=7)\n",
    "for (x, y, w, h) in detections:\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "cv2.imshow('Image', image)\n",
    "cv2.waitKey(0)  # 아무 키 입력 대기\n",
    "cv2.destroyAllWindows()  # 모든 윈도우 닫기"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Eye detection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "car_detector = cv2.CascadeClassifier('/Users/sihoon/Desktop/ComputerVision/Computer Vision Masterclass/Cascades/cars.xml')\n",
    "\n",
    "clocks_detector = cv2.CascadeClassifier('/Users/sihoon/Desktop/ComputerVision/Computer Vision Masterclass/Cascades/clocks.xml')\n",
    "\n",
    "body_detector = cv2.CascadeClassifier('/Users/sihoon/Desktop/ComputerVision/Computer Vision Masterclass/Cascades/fullbody.xml')\n",
    "\n",
    "eye_detector = cv2.CascadeClassifier('/Users/sihoon/Desktop/ComputerVision/Computer Vision Masterclass/Cascades/haarcascade_eye.xml')\n",
    "\n",
    "face_detector = cv2.CascadeClassifier('/Users/sihoon/Desktop/ComputerVision/Computer Vision Masterclass/Cascades/haarcascade_frontalface_default.xml')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('/Users/sihoon/Desktop/ComputerVision/Computer Vision Masterclass/Images/people1.jpg')\n",
    "#image = cv2.resize(image, (800, 600)) # 소요시간을 줄이기 위해 크기 축소\n",
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "face_detections = face_detector.detectMultiScale(image_gray, scaleFactor=1.3, minSize=(30, 30))\n",
    "for (x, y, w, h) in face_detections:\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "eye_detections = eye_detector.detectMultiScale(image_gray, scaleFactor=1.1, minNeighbors=10, maxSize=(70, 70))\n",
    "for (x, y, w, h) in eye_detections:\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "\n",
    "cv2.imshow('Image', image)\n",
    "cv2.waitKey(0)  # 아무 키 입력 대기\n",
    "cv2.destroyAllWindows()  # 모든 윈도우 닫기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## HW"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "car_image = cv2.imread('/Users/sihoon/Desktop/ComputerVision/Computer Vision Masterclass/Images/car.jpg')\n",
    "#image = cv2.resize(image, (800, 600)) # 소요시간을 줄이기 위해 크기 축소\n",
    "car_image_gray = cv2.cvtColor(car_image, cv2.COLOR_BGR2GRAY)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "clock_image = cv2.imread('/Users/sihoon/Desktop/ComputerVision/Computer Vision Masterclass/Images/clock.jpg')\n",
    "#image = cv2.resize(image, (800, 600)) # 소요시간을 줄이기 위해 크기 축소\n",
    "clock_image_gray = cv2.cvtColor(clock_image, cv2.COLOR_BGR2GRAY)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "jump_image = cv2.imread('/Users/sihoon/Desktop/ComputerVision/Computer Vision Masterclass/Images/jump.jpg')\n",
    "#image = cv2.resize(image, (800, 600)) # 소요시간을 줄이기 위해 크기 축소\n",
    "jump_image_gray = cv2.cvtColor(jump_image, cv2.COLOR_BGR2GRAY)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "car_detector = cv2.CascadeClassifier('/Users/sihoon/Desktop/ComputerVision/Computer Vision Masterclass/Cascades/cars.xml')\n",
    "\n",
    "clock_detector = cv2.CascadeClassifier('/Users/sihoon/Desktop/ComputerVision/Computer Vision Masterclass/Cascades/clocks.xml')\n",
    "\n",
    "body_detector = cv2.CascadeClassifier('/Users/sihoon/Desktop/ComputerVision/Computer Vision Masterclass/Cascades/fullbody.xml')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "car_detections = car_detector.detectMultiScale(car_image_gray, scaleFactor=1.1, minNeighbors=5)\n",
    "for (x, y, w, h) in car_detections:\n",
    "    cv2.rectangle(car_image, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "\n",
    "\n",
    "cv2.imshow('Car_Image', car_image)\n",
    "cv2.waitKey(0)  # 아무 키 입력 대기\n",
    "cv2.destroyAllWindows()  # 모든 윈도우 닫기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "clock_detections = clock_detector.detectMultiScale(clock_image_gray, scaleFactor=1.02, minNeighbors=10)\n",
    "for (x, y, w, h) in clock_detections:\n",
    "    cv2.rectangle(clock_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "cv2.imshow('Image', clock_image)\n",
    "cv2.waitKey(0)  # 아무 키 입력 대기\n",
    "cv2.destroyAllWindows()  # 모든 윈도우 닫기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "body_detections = body_detector.detectMultiScale(jump_image_gray, scaleFactor=1.2, minNeighbors=5)\n",
    "for (x, y, w, h) in body_detections:\n",
    "    cv2.rectangle(jump_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "cv2.imshow('Image', jump_image)\n",
    "cv2.waitKey(0)  # 아무 키 입력 대기\n",
    "cv2.destroyAllWindows()  # 모든 윈도우 닫기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Detecting faces with HOG"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import dlib"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "image = cv2.imread('/Users/sihoon/Desktop/ComputerVision/Computer Vision Masterclass/Images/people2.jpg')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "cv2.imshow('Image', image)\n",
    "cv2.waitKey(0)  # 아무 키 입력 대기\n",
    "cv2.destroyAllWindows()  # 모든 윈도우 닫기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "face_detector_hog = dlib.get_frontal_face_detector()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "detections = face_detector_hog(image, 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "data": {
      "text/plain": "rectangles[[(429, 38) (465, 74)], [(665, 90) (701, 126)], [(717, 103) (760, 146)], [(909, 70) (952, 113)], [(828, 98) (871, 142)], [(605, 70) (641, 106)], [(777, 62) (813, 98)], [(485, 78) (521, 114)], [(386, 60) (429, 103)], [(170, 41) (213, 84)], [(93, 89) (136, 132)], [(237, 50) (280, 94)], [(323, 50) (367, 94)], [(544, 65) (588, 108)]]"
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "data": {
      "text/plain": "14"
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(detections)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(429, 38) (465, 74)]\n",
      "[(665, 90) (701, 126)]\n",
      "[(717, 103) (760, 146)]\n",
      "[(909, 70) (952, 113)]\n",
      "[(828, 98) (871, 142)]\n",
      "[(605, 70) (641, 106)]\n",
      "[(777, 62) (813, 98)]\n",
      "[(485, 78) (521, 114)]\n",
      "[(386, 60) (429, 103)]\n",
      "[(170, 41) (213, 84)]\n",
      "[(93, 89) (136, 132)]\n",
      "[(237, 50) (280, 94)]\n",
      "[(323, 50) (367, 94)]\n",
      "[(544, 65) (588, 108)]\n"
     ]
    }
   ],
   "source": [
    "for face in detections:\n",
    "    print(face)\n",
    "\n",
    "# 모든 사람 얼굴의 위치"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "for face in detections:\n",
    "    # print(face.left())\n",
    "    # print(face.top())\n",
    "    # print(face.right())\n",
    "    # print(face.bottom())\n",
    "    l, t, r, b = face.left(), face.top(), face.right(), face.bottom()\n",
    "    cv2.rectangle(image, (l, t), (r, b), (0, 255, 255), 2)\n",
    "\n",
    "cv2.imshow('Image', image)\n",
    "cv2.waitKey(0)  # 아무 키 입력 대기\n",
    "cv2.destroyAllWindows()  # 모든 윈도우 닫기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Detecting faces with CNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "image = cv2.imread('/Users/sihoon/Desktop/ComputerVision/Computer Vision Masterclass/Images/people2.jpg')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# cnn 감지기 사용\n",
    "cnn_detector = dlib.cnn_face_detection_model_v1('/Users/sihoon/Desktop/ComputerVision/Computer Vision Masterclass/Weights/mmod_human_face_detector.dat')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "detections = cnn_detector(image, 4)\n",
    "for face in detections:\n",
    "    l, t, r, b, c = face.rect.left(), face.rect.top(), face.rect.right(), face.rect.bottom(), face.confidence\n",
    "    print(c)\n",
    "    cv2.rectangle(image, (l, t), (r, b), (255, 255, 0), 2)\n",
    "cv2.imshow('Image', image)\n",
    "cv2.waitKey(0)  # 아무 키 입력 대기\n",
    "cv2.destroyAllWindows()  # 모든 윈도우 닫기"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "image = cv2.imread('/Users/sihoon/Desktop/ComputerVision/Computer Vision Masterclass/Images/people3.jpg')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Face detection in Webcam"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
